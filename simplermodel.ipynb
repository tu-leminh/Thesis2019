{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaModel(\n",
      "  (embeddings): RobertaEmbeddings(\n",
      "    (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
      "    (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
      "    (token_type_embeddings): Embedding(1, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): RobertaEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): RobertaPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>channel_category</th>\n",
       "      <th>channel_started</th>\n",
       "      <th>channel_rank</th>\n",
       "      <th>channel_subscribers</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>title_length</th>\n",
       "      <th>categories</th>\n",
       "      <th>...</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>like_per_view</th>\n",
       "      <th>comment_per_view</th>\n",
       "      <th>dislike_per_view</th>\n",
       "      <th>engagement_rate_1</th>\n",
       "      <th>engagement_rate_2</th>\n",
       "      <th>q_score</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UC0jDoh3tVXCaqJ6oTve8ebA</td>\n",
       "      <td>FAP TV</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>12800000</td>\n",
       "      <td>nehrVdADdH0</td>\n",
       "      <td>[FAP TV ] Thông Báo Tuyển Diễn Viên Nam Film L...</td>\n",
       "      <td>14</td>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>...</td>\n",
       "      <td>827</td>\n",
       "      <td>105</td>\n",
       "      <td>0.020731</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.023187</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>0.970364</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UC0jDoh3tVXCaqJ6oTve8ebA</td>\n",
       "      <td>FAP TV</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>12800000</td>\n",
       "      <td>K66wOEaBwK4</td>\n",
       "      <td>Phía Sau Một Cô Gái - Soobin Hoàng Sơn | MV Fa...</td>\n",
       "      <td>14</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>...</td>\n",
       "      <td>1594</td>\n",
       "      <td>664</td>\n",
       "      <td>0.010124</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.010746</td>\n",
       "      <td>0.011005</td>\n",
       "      <td>0.950070</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UC0jDoh3tVXCaqJ6oTve8ebA</td>\n",
       "      <td>FAP TV</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>12800000</td>\n",
       "      <td>D00vn3X7oI8</td>\n",
       "      <td>FAPtv Cơm Nguội: Tập 94 - Dấu Ấn Học Đường Phần 2</td>\n",
       "      <td>12</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>...</td>\n",
       "      <td>2214</td>\n",
       "      <td>3089</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.006568</td>\n",
       "      <td>0.896920</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UC0jDoh3tVXCaqJ6oTve8ebA</td>\n",
       "      <td>FAP TV</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>12800000</td>\n",
       "      <td>G22G1k3G-kM</td>\n",
       "      <td>FAPtv Cơm Nguội: Tập 100 - Hành Trình Vui Vẻ</td>\n",
       "      <td>10</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>...</td>\n",
       "      <td>1752</td>\n",
       "      <td>2202</td>\n",
       "      <td>0.007931</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.008159</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>0.930209</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UC0jDoh3tVXCaqJ6oTve8ebA</td>\n",
       "      <td>FAP TV</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>12800000</td>\n",
       "      <td>G5EG7ymPErw</td>\n",
       "      <td>FAPtv Cơm Nguội: Tập 95 - Dấu Ấn Học Đường Phầ...</td>\n",
       "      <td>12</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>...</td>\n",
       "      <td>2417</td>\n",
       "      <td>2208</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>0.918029</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 channel_id channel_name channel_category  channel_started  \\\n",
       "0  UC0jDoh3tVXCaqJ6oTve8ebA       FAP TV           Comedy             2014   \n",
       "1  UC0jDoh3tVXCaqJ6oTve8ebA       FAP TV           Comedy             2014   \n",
       "2  UC0jDoh3tVXCaqJ6oTve8ebA       FAP TV           Comedy             2014   \n",
       "3  UC0jDoh3tVXCaqJ6oTve8ebA       FAP TV           Comedy             2014   \n",
       "4  UC0jDoh3tVXCaqJ6oTve8ebA       FAP TV           Comedy             2014   \n",
       "\n",
       "   channel_rank  channel_subscribers           id  \\\n",
       "0             2             12800000  nehrVdADdH0   \n",
       "1             2             12800000  K66wOEaBwK4   \n",
       "2             2             12800000  D00vn3X7oI8   \n",
       "3             2             12800000  G22G1k3G-kM   \n",
       "4             2             12800000  G5EG7ymPErw   \n",
       "\n",
       "                                               title  title_length  \\\n",
       "0  [FAP TV ] Thông Báo Tuyển Diễn Viên Nam Film L...            14   \n",
       "1  Phía Sau Một Cô Gái - Soobin Hoàng Sơn | MV Fa...            14   \n",
       "2  FAPtv Cơm Nguội: Tập 94 - Dấu Ấn Học Đường Phần 2            12   \n",
       "3       FAPtv Cơm Nguội: Tập 100 - Hành Trình Vui Vẻ            10   \n",
       "4  FAPtv Cơm Nguội: Tập 95 - Dấu Ấn Học Đường Phầ...            12   \n",
       "\n",
       "         categories  ... comment_count dislike_count  like_per_view  \\\n",
       "0  Film & Animation  ...           827           105       0.020731   \n",
       "1            Comedy  ...          1594           664       0.010124   \n",
       "2     Entertainment  ...          2214          3089       0.006007   \n",
       "3     Entertainment  ...          1752          2202       0.007931   \n",
       "4     Entertainment  ...          2417          2208       0.006485   \n",
       "\n",
       "  comment_per_view  dislike_per_view  engagement_rate_1  engagement_rate_2  \\\n",
       "0         0.002456          0.000312           0.023187           0.023499   \n",
       "1         0.000622          0.000259           0.010746           0.011005   \n",
       "2         0.000234          0.000326           0.006241           0.006568   \n",
       "3         0.000228          0.000287           0.008159           0.008446   \n",
       "4         0.000303          0.000277           0.006789           0.007066   \n",
       "\n",
       "    q_score  label_1  label_2  \n",
       "0  0.970364        2        2  \n",
       "1  0.950070        1        2  \n",
       "2  0.896920        1        2  \n",
       "3  0.930209        1        2  \n",
       "4  0.918029        1        2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from multihead_attention import MultiheadAttention\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "print(phobert)\n",
    "\n",
    "# For transformers v4.x+: \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n",
    "\n",
    "\n",
    "ENTUBE = 'entube.parquet'\n",
    "entube = pd.read_parquet(ENTUBE)\n",
    "entube.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encode(text,s=100):\n",
    "    temp=tokenizer.encode(text)\n",
    "    while len(temp)<s:\n",
    "        temp.append(1)\n",
    "    input_ids = torch.tensor(temp[:s])\n",
    "    return input_ids\n",
    "\n",
    "def get_tags_encode(tags_list):\n",
    "  return get_encode(\" \".join([i for i in tags_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nehrVdADdH0</td>\n",
       "      <td>[FAP TV ] Thông Báo Tuyển Diễn Viên Nam Film L...</td>\n",
       "      <td>[phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K66wOEaBwK4</td>\n",
       "      <td>Phía Sau Một Cô Gái - Soobin Hoàng Sơn | MV Fa...</td>\n",
       "      <td>[phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D00vn3X7oI8</td>\n",
       "      <td>FAPtv Cơm Nguội: Tập 94 - Dấu Ấn Học Đường Phần 2</td>\n",
       "      <td>[phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G22G1k3G-kM</td>\n",
       "      <td>FAPtv Cơm Nguội: Tập 100 - Hành Trình Vui Vẻ</td>\n",
       "      <td>[phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G5EG7ymPErw</td>\n",
       "      <td>FAPtv Cơm Nguội: Tập 95 - Dấu Ấn Học Đường Phầ...</td>\n",
       "      <td>[phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26231</th>\n",
       "      <td>3Dn6gHcMMxw</td>\n",
       "      <td>Hot: Cha Đẻ \"ATM gạo\" Lần Đầu Ra Mắt \"ATM khẩu...</td>\n",
       "      <td>[Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26232</th>\n",
       "      <td>GhxY-7QwD_c</td>\n",
       "      <td>Đường Thành Sông, Nhà Thành Hầm Chứa Nước Sau ...</td>\n",
       "      <td>[Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26233</th>\n",
       "      <td>MwqkdX9lyuk</td>\n",
       "      <td>AEON MALL Bình Tân Quá Th.ê Thảm, Vắ.ng Hoe Vì...</td>\n",
       "      <td>[Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26234</th>\n",
       "      <td>3dHgXfekVjo</td>\n",
       "      <td>Sài Gòn Ngập Khắp Nơi Từ Chiều Đến Đêm, Ngang ...</td>\n",
       "      <td>[Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26235</th>\n",
       "      <td>tpXTz_0FjEA</td>\n",
       "      <td>Nước Chảy Cuồn Cuộn Như Thác Lũ Trên Phố Sài G...</td>\n",
       "      <td>[Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26236 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                              title  \\\n",
       "0      nehrVdADdH0  [FAP TV ] Thông Báo Tuyển Diễn Viên Nam Film L...   \n",
       "1      K66wOEaBwK4  Phía Sau Một Cô Gái - Soobin Hoàng Sơn | MV Fa...   \n",
       "2      D00vn3X7oI8  FAPtv Cơm Nguội: Tập 94 - Dấu Ấn Học Đường Phần 2   \n",
       "3      G22G1k3G-kM       FAPtv Cơm Nguội: Tập 100 - Hành Trình Vui Vẻ   \n",
       "4      G5EG7ymPErw  FAPtv Cơm Nguội: Tập 95 - Dấu Ấn Học Đường Phầ...   \n",
       "...            ...                                                ...   \n",
       "26231  3Dn6gHcMMxw  Hot: Cha Đẻ \"ATM gạo\" Lần Đầu Ra Mắt \"ATM khẩu...   \n",
       "26232  GhxY-7QwD_c  Đường Thành Sông, Nhà Thành Hầm Chứa Nước Sau ...   \n",
       "26233  MwqkdX9lyuk  AEON MALL Bình Tân Quá Th.ê Thảm, Vắ.ng Hoe Vì...   \n",
       "26234  3dHgXfekVjo  Sài Gòn Ngập Khắp Nơi Từ Chiều Đến Đêm, Ngang ...   \n",
       "26235  tpXTz_0FjEA  Nước Chảy Cuồn Cuộn Như Thác Lũ Trên Phố Sài G...   \n",
       "\n",
       "                                                    tags  label_2  \n",
       "0      [phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...        2  \n",
       "1      [phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...        2  \n",
       "2      [phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...        2  \n",
       "3      [phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...        2  \n",
       "4      [phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...        2  \n",
       "...                                                  ...      ...  \n",
       "26231    [Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]        1  \n",
       "26232    [Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]        1  \n",
       "26233    [Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]        1  \n",
       "26234    [Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]        1  \n",
       "26235    [Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]        1  \n",
       "\n",
       "[26236 rows x 4 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entube_data = entube[['id','title','tags','label_2']]\n",
    "entube_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtthe\\AppData\\Local\\Temp\\ipykernel_11584\\3004365453.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entube_data['encode_title'] = entube_data['title'].apply(get_encode)\n",
      "C:\\Users\\mtthe\\AppData\\Local\\Temp\\ipykernel_11584\\3004365453.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entube_data['encode_tag'] = entube_data['tags'].apply(get_tags_encode)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>label_2</th>\n",
       "      <th>encode_title</th>\n",
       "      <th>encode_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nehrVdADdH0</td>\n",
       "      <td>[FAP TV ] Thông Báo Tuyển Diễn Viên Nam Film L...</td>\n",
       "      <td>[phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0), tensor(63576), tensor(1579), tenso...</td>\n",
       "      <td>[tensor(0), tensor(266), tensor(82), tensor(15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K66wOEaBwK4</td>\n",
       "      <td>Phía Sau Một Cô Gái - Soobin Hoàng Sơn | MV Fa...</td>\n",
       "      <td>[phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0), tensor(2696), tensor(162), tensor(...</td>\n",
       "      <td>[tensor(0), tensor(266), tensor(82), tensor(15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D00vn3X7oI8</td>\n",
       "      <td>FAPtv Cơm Nguội: Tập 94 - Dấu Ấn Học Đường Phần 2</td>\n",
       "      <td>[phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0), tensor(1579), tensor(8607), tensor...</td>\n",
       "      <td>[tensor(0), tensor(266), tensor(82), tensor(15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G22G1k3G-kM</td>\n",
       "      <td>FAPtv Cơm Nguội: Tập 100 - Hành Trình Vui Vẻ</td>\n",
       "      <td>[phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0), tensor(1579), tensor(8607), tensor...</td>\n",
       "      <td>[tensor(0), tensor(266), tensor(82), tensor(15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G5EG7ymPErw</td>\n",
       "      <td>FAPtv Cơm Nguội: Tập 95 - Dấu Ấn Học Đường Phầ...</td>\n",
       "      <td>[phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0), tensor(1579), tensor(8607), tensor...</td>\n",
       "      <td>[tensor(0), tensor(266), tensor(82), tensor(15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26231</th>\n",
       "      <td>3Dn6gHcMMxw</td>\n",
       "      <td>Hot: Cha Đẻ \"ATM gạo\" Lần Đầu Ra Mắt \"ATM khẩu...</td>\n",
       "      <td>[Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0), tensor(16261), tensor(27), tensor(...</td>\n",
       "      <td>[tensor(0), tensor(350), tensor(590), tensor(4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26232</th>\n",
       "      <td>GhxY-7QwD_c</td>\n",
       "      <td>Đường Thành Sông, Nhà Thành Hầm Chứa Nước Sau ...</td>\n",
       "      <td>[Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0), tensor(2080), tensor(1206), tensor...</td>\n",
       "      <td>[tensor(0), tensor(350), tensor(590), tensor(4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26233</th>\n",
       "      <td>MwqkdX9lyuk</td>\n",
       "      <td>AEON MALL Bình Tân Quá Th.ê Thảm, Vắ.ng Hoe Vì...</td>\n",
       "      <td>[Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0), tensor(40989), tensor(11778), tens...</td>\n",
       "      <td>[tensor(0), tensor(350), tensor(590), tensor(4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26234</th>\n",
       "      <td>3dHgXfekVjo</td>\n",
       "      <td>Sài Gòn Ngập Khắp Nơi Từ Chiều Đến Đêm, Ngang ...</td>\n",
       "      <td>[Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0), tensor(10696), tensor(26328), tens...</td>\n",
       "      <td>[tensor(0), tensor(350), tensor(590), tensor(4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26235</th>\n",
       "      <td>tpXTz_0FjEA</td>\n",
       "      <td>Nước Chảy Cuồn Cuộn Như Thác Lũ Trên Phố Sài G...</td>\n",
       "      <td>[Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0), tensor(2837), tensor(33020), tenso...</td>\n",
       "      <td>[tensor(0), tensor(350), tensor(590), tensor(4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26236 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                              title  \\\n",
       "0      nehrVdADdH0  [FAP TV ] Thông Báo Tuyển Diễn Viên Nam Film L...   \n",
       "1      K66wOEaBwK4  Phía Sau Một Cô Gái - Soobin Hoàng Sơn | MV Fa...   \n",
       "2      D00vn3X7oI8  FAPtv Cơm Nguội: Tập 94 - Dấu Ấn Học Đường Phần 2   \n",
       "3      G22G1k3G-kM       FAPtv Cơm Nguội: Tập 100 - Hành Trình Vui Vẻ   \n",
       "4      G5EG7ymPErw  FAPtv Cơm Nguội: Tập 95 - Dấu Ấn Học Đường Phầ...   \n",
       "...            ...                                                ...   \n",
       "26231  3Dn6gHcMMxw  Hot: Cha Đẻ \"ATM gạo\" Lần Đầu Ra Mắt \"ATM khẩu...   \n",
       "26232  GhxY-7QwD_c  Đường Thành Sông, Nhà Thành Hầm Chứa Nước Sau ...   \n",
       "26233  MwqkdX9lyuk  AEON MALL Bình Tân Quá Th.ê Thảm, Vắ.ng Hoe Vì...   \n",
       "26234  3dHgXfekVjo  Sài Gòn Ngập Khắp Nơi Từ Chiều Đến Đêm, Ngang ...   \n",
       "26235  tpXTz_0FjEA  Nước Chảy Cuồn Cuộn Như Thác Lũ Trên Phố Sài G...   \n",
       "\n",
       "                                                    tags  label_2  \\\n",
       "0      [phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...        2   \n",
       "1      [phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...        2   \n",
       "2      [phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...        2   \n",
       "3      [phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...        2   \n",
       "4      [phim hai, FAPtv, FAPtivi, cơm nguội, Ribi Sac...        2   \n",
       "...                                                  ...      ...   \n",
       "26231    [Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]        1   \n",
       "26232    [Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]        1   \n",
       "26233    [Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]        1   \n",
       "26234    [Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]        1   \n",
       "26235    [Việt Nam Fly, Việt Nam, Fly, Việt Nam bay cao]        1   \n",
       "\n",
       "                                            encode_title  \\\n",
       "0      [tensor(0), tensor(63576), tensor(1579), tenso...   \n",
       "1      [tensor(0), tensor(2696), tensor(162), tensor(...   \n",
       "2      [tensor(0), tensor(1579), tensor(8607), tensor...   \n",
       "3      [tensor(0), tensor(1579), tensor(8607), tensor...   \n",
       "4      [tensor(0), tensor(1579), tensor(8607), tensor...   \n",
       "...                                                  ...   \n",
       "26231  [tensor(0), tensor(16261), tensor(27), tensor(...   \n",
       "26232  [tensor(0), tensor(2080), tensor(1206), tensor...   \n",
       "26233  [tensor(0), tensor(40989), tensor(11778), tens...   \n",
       "26234  [tensor(0), tensor(10696), tensor(26328), tens...   \n",
       "26235  [tensor(0), tensor(2837), tensor(33020), tenso...   \n",
       "\n",
       "                                              encode_tag  \n",
       "0      [tensor(0), tensor(266), tensor(82), tensor(15...  \n",
       "1      [tensor(0), tensor(266), tensor(82), tensor(15...  \n",
       "2      [tensor(0), tensor(266), tensor(82), tensor(15...  \n",
       "3      [tensor(0), tensor(266), tensor(82), tensor(15...  \n",
       "4      [tensor(0), tensor(266), tensor(82), tensor(15...  \n",
       "...                                                  ...  \n",
       "26231  [tensor(0), tensor(350), tensor(590), tensor(4...  \n",
       "26232  [tensor(0), tensor(350), tensor(590), tensor(4...  \n",
       "26233  [tensor(0), tensor(350), tensor(590), tensor(4...  \n",
       "26234  [tensor(0), tensor(350), tensor(590), tensor(4...  \n",
       "26235  [tensor(0), tensor(350), tensor(590), tensor(4...  \n",
       "\n",
       "[26236 rows x 6 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entube_data['encode_title'] = entube_data['title'].apply(get_encode)\n",
    "entube_data['encode_tag'] = entube_data['tags'].apply(get_tags_encode)\n",
    "entube_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "class SimplerModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimplerModel, self).__init__()\n",
    "\n",
    "        self.phobert_title = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "        self.title_LayerNorm = nn.LayerNorm(768)\n",
    "        self.title_MultiheadAttention = nn.MultiheadAttention(768,1)\n",
    "        self.title_Linear = nn.Linear(768, 1024)\n",
    "\n",
    "\n",
    "        self.phobert_tag = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "        self.tag_LayerNorm = nn.LayerNorm(768)\n",
    "        self.tag_MultiheadAttention = nn.MultiheadAttention(768,1)\n",
    "        self.tag_Linear = nn.Linear(768, 1024)\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "                nn.BatchNorm1d(2),\n",
    "                nn.Conv1d(2, 1, 1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        self.cf = nn.Linear(1024,3)\n",
    "    def forward(self, X):\n",
    "        if (len(X.shape)==1):\n",
    "            X = X[None,:]\n",
    "        X_title = X[:,:100]\n",
    "        X_tag = X[:,100:]\n",
    "\n",
    "        print(X_title.shape)\n",
    "        with torch.no_grad():\n",
    "            x_title = self.phobert_title(X_title)\n",
    "        x_title = x_title['pooler_output']\n",
    "        x_title_1 = x_title\n",
    "        x_title = self.title_LayerNorm(x_title)\n",
    "        x_title,_ = self.title_MultiheadAttention(x_title,x_title,x_title)\n",
    "        x_title=x_title+x_title_1\n",
    "        x_title = self.title_Linear(x_title)\n",
    "        x_title = x_title[:,None,:]\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x_tag = self.phobert_tag(X_tag)\n",
    "        x_tag = x_tag['pooler_output']\n",
    "        x_tag_1 = x_tag\n",
    "        x_tag = self.tag_LayerNorm(x_tag)\n",
    "        x_tag,_ = self.tag_MultiheadAttention(x_tag,x_tag,x_tag)\n",
    "        x_tag=x_tag+x_tag_1\n",
    "        x_tag = self.tag_Linear(x_tag)\n",
    "        x_tag = x_tag[:,None,:]\n",
    "\n",
    "        \n",
    "        x = torch.concat((x_title, x_tag), dim=1)\n",
    "        x = self.conv(x)\n",
    "        x = F.dropout(x, 0.1)\n",
    "        x = self.cf(x)\n",
    "        return torch.squeeze(x)\n",
    "simplermodel = SimplerModel()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device} device')\n",
    "simplermodel = simplermodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index].to_numpy()\n",
    "        features =  torch.cat((row[4],row[5]),0)\n",
    "        label = row[3]\n",
    "        return features, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "data = CustomDataset(dataframe=entube_data)\n",
    "dataloader = DataLoader(data, batch_size = 20, drop_last=True,shuffle=True)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(data))\n",
    "test_size = len(data) - train_size\n",
    "generator = torch.Generator().manual_seed(123)\n",
    "train_loader, val_loader = torch.utils.data.random_split(data, [train_size, test_size],generator=generator)\n",
    "trainloader = DataLoader(train_loader, batch_size=32)\n",
    "validloader = DataLoader(val_loader, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(simplermodel.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"saved_model.pth\"\n",
    "simplermodel.load_state_dict(torch.load(PATH))\n",
    "\n",
    "def valid(e,train_loss,min_valid_loss = np.inf):\n",
    "    valid_loss = 0.0\n",
    "    simplermodel.eval()\n",
    "    for data, labels in validloader:\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "        target = simplermodel(data)\n",
    "        loss = criterion(target,labels)\n",
    "        valid_loss+= loss.item()\n",
    "\n",
    "    print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss / len(trainloader)} \\t\\t Validation Loss: {valid_loss / len(validloader)}')\n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        torch.save(simplermodel.state_dict(), PATH)\n",
    "    return min_valid_loss\n",
    "def train():\n",
    "    train_loss = 0.0\n",
    "    simplermodel.train()\n",
    "    for data, labels in tqdm(trainloader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        target = simplermodel(data)\n",
    "        loss = criterion(target,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "Epoch 1 \t\t Training Loss: 0.0 \t\t Validation Loss: 0.7902444188551205\n",
      "Validation Loss Decreased(inf--->129.600085) \t Saving The Model\n"
     ]
    }
   ],
   "source": [
    "epochs=0\n",
    "\n",
    "min_valid_loss=valid(0,0)\n",
    "for e in range(epochs):\n",
    "    train_loss=train()\n",
    "    min_valid_loss=valid(e,train_loss,min_valid_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
